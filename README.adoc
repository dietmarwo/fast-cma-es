:encoding: utf-8
:imagesdir: tutorials/img
:cpp: C++

= fcmaes - a Python 3 gradient-free optimization library

https://gitter.im/fast-cma-es/community[image:https://badges.gitter.im/Join%20Chat.svg[]]

fcmaes complements https://docs.scipy.org/doc/scipy/reference/optimize.html[scipy optimize] by providing 
additional optimization methods, faster {cpp}/Eigen based implementations and a coordinated parallel retry mechanism. 
It supports the multi threaded application of different gradient free optimization algorithms. 

fcmaes started as a fast CMA-ES implementation combined with a new smart parallel retry mechanism aimed to solve
hard optimization problems from the space flight planning domain. It evolved to a general library of
state-of-the-art gradient free optimization algorithms applicable to all kind of real world problems covering
multi-objective and constrained problems. Its main algorithms are implemented both in Python and C++ and
support both parallel fitness function evaluation and a parallel retry mechanism. 

=== Documentation

- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/Tutorial.adoc[Tutorial] Solving simple example problems from space flight dynamics.  
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/CryptoTrading.adoc[Crypto Trading] Optimize your crypto trading strategy.  
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/Water.adoc[Water Management] Optimize water resource management.  
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/UAV.adoc[Multi-UAV] Multi-UAV Task Assignment.  
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/PowerPlant.adoc[Power Plant] Power Plant Efficiency.  
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/Routing.adoc[Routing] Capacitated Vehicle Routing.
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/Surrogate.adoc[Surrogate] Optimize the Mazda car design problem.  
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/RobotRover.adoc[Robot Pushing and Navigating Rovers]
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/FluidDynamics.adoc[CFD] Optimize CFD simulation based problems.  
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/TSP.adoc[Noisy TSP] Solve the noisy Traveling Salesman Problem.  
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/Hospital.adoc[Hospital] Managing hospital resources during a pandemic.  
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/JobShop.adoc[JobShop] Solving the flexible job shop scheduling problem. 
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/Scheduling.adoc[Scheduling] Solving a complex scheduling problem, part of the GTOC11 competition.
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/SpaceFlight.adoc[Space Flight] Space flight mission design revisited.
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/MODE.adoc[MO-DE] MO-DE, a new multi objective algorithm.
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/MultiObjective.adoc[Multi-Objective] Solving multi objective problems using variable weights. 
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/TopTrumps.adoc[gbea TopTrumps Benchmark] TopTrumps game optimization benchmark. 
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/PAGMO.adoc[Pagmo results] GTOPX Benchmark results using Pagmo
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/PYKEP.adoc[Pykep gym results] Benchmark results for the Pykep gym problems
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/Constraints.adoc[Constraints] Optimizing with constraints. 
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/Expressions.adoc[Expressions] Sequences and random choices of optimizers. 
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/ODE.adoc[ODE] Use of differential equation solvers. 
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/HyperparameterOptimization.adoc[Hyper Parameters] Hyper parameter optimization.
- https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/DelayedUpdate.adoc[Delayed Update] Asynchronous parallel function evaluation.

=== Features

- fcmaes is focused on optimization problems hard to solve utilizing modern many-core CPUs.
- Parallel fitness function evaluation and different parallel retry mechanisms. 
- Minimized algorithm overhead - relative to the objective function evaluation time - even for high dimensions. 
- New multi-objective/constrained optimization algorithm MODE combining features from Differential evolution and NSGA-II, supporting parallel function evaluation. Features https://www.jstage.jst.go.jp/article/tjpnsec/11/2/11_18/_article/-char/en/[enhanced multiple constraint ranking] improving its performance in handling constraints for engineering design optimization.
- BiteOpt algorithm from Aleksey Vaneev.
- New DE (differential evolution) variant optimized for usage with parallel retry.
- GCL-DE (differential evolution) variant from Mingcheng Zuo.
- NEW: DE and MODE now have explicit support for mixed integer problems. https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/TSP.adoc[Noisy TSP] shows the performance improvement. Use one of these algorithms when your problem contains discrete arguments and add 
the `ints` parameter which specifies which parameters are discrete. Real world mixed integer problems like 
https://github.com/AlgTUDelft/ExpensiveOptimBenchmark/blob/master/expensiveoptimbenchmark/problems/DockerCFDBenchmark.py[ESP/ESP2] cannot
be solved without. 
- NEW: Python and C++ implementation of Fast Moving Natural Evolution Strategy for High-Dimensional Problems (CR-FM-NES), see 
    https://arxiv.org/abs/2201.11422. Derived from https://github.com/nomuramasahir0/crfmnes -

=== Performance

==== Engineering Design Optimization

In this domain we often have multiple competing objectives and a lot of constraints. We present results for the
http://ladse.eng.isas.jaxa.jp/benchmark/[Mazda real-world car structure design benchmark], the simultaneous
optimization of three car models minimizing their weight, increasing the number of shared thicknesses of structural  
parts thereby fulfilling 54 constraints. 2017 there was a competition related to this problem https://www.jstage.jst.go.jp/article/tjpnsec/9/2/9_86/_article/-char/en[Report of Evolutionary Computation Competition 2017],
but until now not many of the ideas produced there have found their way into open source optimization libraries. 

We applied https://github.com/dietmarwo/fast-cma-es/blob/master/fcmaes/modecpp.py[modecpp.py] for 
about 1 hour runtime using one AMD 5950x CPU on Linux, de/rand/1 strategy (nsga_update=False, pareto_update=False, ints=[True]*dim), 
population size = 256. We choose the best run out of two executed in parallel, each utilizing 16 threads (workers=16). 
This way about 8200 function evaluations are performed per second for both runs combined.  

The resulting pareto front with hypervolume 0.4074 is:

image::mazda.png[] 

The "reference" NSGA-II solution given as part of the benchmark has hypervolume 0.1456:

image::mazda0.png[]

Note, that the reference solution was computed using a limited budget. But NSGA-II scales much worse than fcmaes-MoDe
using https://www.jstage.jst.go.jp/article/tjpnsec/11/2/11_18/_article/-char/en/[enhanced multiple constraint ranking]. 

==== Space Flight Trajectory Planning

fcmaes provides fast parallel
https://github.com/dietmarwo/fast-cma-es/blob/master/examples/advexamples.py[example solvers] for the 
real world space flight design problems https://www.esa.int/gsp/ACT/projects/gtop[GTOP] and for 
the https://mintoc.de/index.php/F-8_aircraft[F-8_aircraft] problem based on differential equations. 
On http://www.midaco-solver.com/index.php/about/benchmarks/gtopx[GTOPX] you can find implementations 
of the corresponding objective functions using different programming languages. The
solution times given in the tables below are for Linux / AMD 5950x CPU.

.GTOP coordinated retry results for stopVal = 1.005*absolute_best
[width="80%",cols="3,^2,^2,^2,^2,^2,^2",options="header"]
|=========================================================
|problem |runs | absolute best |stopVal |success rate |mean time|sdev time
|Cassini1 |100 |4.9307 |4.95535 |98% |7.43s |10.7s
|Cassini2 |100 |8.383 |8.42491 |97% |55.18s |39.79s
|Gtoc1 |100 |-1581950 |-1574080 |100% |25.88s |22.15s
|Messenger |100 |8.6299 |8.67305 |100% |18.12s |15.48s
|Rosetta |100 |1.3433 |1.35002 |100% |25.05s |10.5s
|Tandem EVEES Constrained |100 |-1500.46 |-1493 |68% |519.21s |479.46s
|Sagas |100 |18.188 |18.279 |99% |7.59s |6.91s
|Messenger Full |100 |1.9579 |1.96769 |41% |3497.25s |2508.88s
|Messenger Full |100 |1.9579 |2.0 |59% |1960.68s |2024.24s
|=========================================================

Note that 'stopVal' is the threshold value determining success and
'mean time' includes the time for failed runs.
Execute https://github.com/dietmarwo/fast-cma-es/blob/master/examples/benchmark_gtop.py[benchmark_gtop.py]
to reproduce these results. The same optimization algorithm
was applied for all problems, using the same parameters both for the optimization algorithm and the coordinated retry.

.GTOP coordinated retry results for reaching the absolute best value
[width="80%",cols="2,^2,^2,^2,^2,^2,^2",options="header"]
|=========================================================
|problem |runs |absolute best |stopVal |success rate |mean time|sdev time
|Cassini1 |100 |4.9307 |4.93075 |98% |8.73s |10.85s
|Cassini2 |100 |8.383 |8.38305 |44% |310.18s |283.52s
|Gtoc1 |100 |-1581950 |-1581949 |100% |46.41s |35.57s
|Messenger |100 |8.6299 |8.62995 |98% |57.91s |39.97s
|Rosetta |100 |1.3433 |1.34335 |27% |268.18s |207.59s
|Tandem |100 |-1500.46 |-1500 |65% |564.26s |517.94s
|Sagas |100 |18.188 |18.189 |99% |8.76s |7.01s
|=========================================================

=== Optimization algorithms

To utilize modern many-core processors all single-objective algorithms should be used with the parallel retry for cheap fitness functions, otherwise use parallel function evaluation.  

- MO-DE: A new multi-objective optimization algorithm merging concepts from differential evolution and NSGA. 
Implemented both in https://github.com/dietmarwo/fast-cma-es/blob/master/fcmaes/mode.py[Python] and in https://github.com/dietmarwo/fast-cma-es/blob/master/_fcmaescpp/modeoptimizer.cpp[C++]. Provides an ask/tell interface and supports constraints and parallel function evaluation. 
Can also be applied to single-objective problems with constraints. Supports mixed integer problems (see https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/FluidDynamics.adoc[CFD] for details)

- BiteOpt algorithm from Aleksey Vaneev https://github.com/avaneev/biteopt[BiteOpt]. Only a C++ version is provided. If your problem is single objective and if you have no clue what algorithm to apply, try this first. Works well with almost all problems. For constraints you have to use weighted penalties.

- Differential Evolution: Implemented both in https://github.com/dietmarwo/fast-cma-es/blob/master/fcmaes/de.py[Python] and in https://github.com/dietmarwo/fast-cma-es/blob/master/_fcmaescpp/deoptimizer.cpp[C++]. Additional concepts implemented are 
https://www.researchgate.net/publication/309179699_Differential_evolution_for_protein_folding_optimization_based_on_a_three-dimensional_AB_off-lattice_model[temporal locality], stochastic reinitialization of individuals based on their age and oscillating CR/F parameters. Provides an ask/tell interface and supports parallel function evaluation. Supports mixed integer problems (see https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/FluidDynamics.adoc[CFD] for details)

- CMA-ES: Implemented both in https://github.com/dietmarwo/fast-cma-es/blob/master/fcmaes/cmaes.py[Python] and in https://github.com/dietmarwo/fast-cma-es/blob/master/_fcmaescpp/acmaesoptimizer.cpp[C++]. Provides an ask/tell interface and supports parallel function evaluation.

- CR-FM-NES: Fast Moving Natural Evolution Strategy for High-Dimensional Problems, see 
    https://arxiv.org/abs/2201.11422. Derived from https://github.com/nomuramasahir0/crfmnes .
Implemented both in https://github.com/dietmarwo/fast-cma-es/blob/master/fcmaes/crfmnes.py[Python] and in https://github.com/dietmarwo/fast-cma-es/blob/master/_fcmaescpp/crfmnes.cpp[C++].
 
- GCL-DE: Eigen based implementation in https://github.com/dietmarwo/fast-cma-es/blob/master/_fcmaescpp/gcldeoptimizer.cpp[C++]. See "A case learning-based differential evolution algorithm for global optimization of interplanetary trajectory design, Mingcheng Zuo, Guangming Dai, Lei Peng, Maocai Wang, Zhengquan Liu", https://doi.org/10.1016/j.asoc.2020.106451[doi].

- Dual Annealing: Eigen based implementation in https://github.com/dietmarwo/fast-cma-es/blob/master/_fcmaescpp/daoptimizer.cpp[C++]. Use the https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.dual_annealing.html[scipy implementation] if you prefer a pure python variant or need more configuration options. 

- Expressions: There are two operators for constructing expressions over optimization algorithms: Sequence and random choice.
Not only the five single objective algorithms above, but also scipy and NLopt optimization methods and custom algorithms can be used for defining algorithm expressions. 
 
 
=== Installation


==== Linux
 
* `pip install fcmaes`. 

To use the {cpp} optimizers a gcc-9.3 (or newer) runtime is required. This is the default on newer Linux versions. 
If you are on an old Linux distribution you need to install gcc-9 or a newer 
version. On ubuntu this is: 

- sudo add-apt-repository ppa:ubuntu-toolchain-r/test
- sudo apt update
- sudo apt install gcc-9

If you have a new anaconda version installed, the required gcc runtime libraries should already be there. 

==== Windows

* `pip install fcmaes`

* install {cpp} runtime libraries https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads

* install https://docs.epics-controls.org/projects/how-tos/en/latest/getting-started/installation-windows-msys2.html[MSYS2] using mingw-64:

- download and install the MSYS2 installer https://www.msys2.org/ . 
- start a MSYS2 shell then execute:
- pacman -S mingw-w64-ucrt-x86_64-cmake
- pacman -S mingw-w64-ucrt-x86_64-gcc
- pacman -S mingw-w64-ucrt-x86_64-ninja
- pacman -S mingw-w64-ucrt-x86_64-jemalloc
- pacman -S mingw-w64-ucrt-x86_64-python
- pacman -S mingw-w64-ucrt-x86_64-python-pip
- pacman -S mingw-w64-ucrt-x86_64-python-scipy
- pacman -S mingw-w64-ucrt-x86_64-python-matplotlib
- pacman -S mingw-w64-ucrt-x86_64-python-numba

Make sure that the MSYS2 mingw-w64 ucrt binary path is set in your environment. 
If you have anaconda or other mingw versions installed, make sure there is no path priority issue. 
For fcmaes it is better to use the MSYS2 python installation. 

Parallel fitness function evaluation works only with the native Python optimizers, not with the {cpp} ones. Use "workers = 1" for the 
{cpp}-optimizers. Python multiprocessing is currently generally flawed on Windows. 
To get optimal scaling from parallel retry and parallel function evaluation use:

* Linux subsystem for Windows https://docs.microsoft.com/en-us/windows/wsl/[WSL].

The Linux subsystem can read/write NTFS, so you can do your development on a NTFS partition. Just the Python call is routed to Linux. 
If performance of the fitness function is an issue and you don't want to use the Linux subsystem for Windows, 
think about using the fcmaes java port: https://github.com/dietmarwo/fcmaes-java[fcmaes-java]. 

==== MacOS

* `pip install fcmaes`

=== Usage

Usage is similar to https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html[scipy.optimize.minimize].

For parallel retry use:

[source,python]
----
from fcmaes.optimizer import logger
from fcmaes import retry
ret = retry.minimize(fun, bounds, logger=logger())
----

The retry logs mean and standard deviation of the results, so it can be used to test and compare optimization algorithms:
You may choose different algorithms for the retry:

[source,python]
----
from fcmaes.optimizer import logger, Bite_cpp, De_cpp, Cma_cpp, Sequence
ret = retry.minimize(fun, bounds, logger=logger(), optimizer=Bite_cpp(100000))
ret = retry.minimize(fun, bounds, logger=logger(), optimizer=De_cpp(100000))
ret = retry.minimize(fun, bounds, logger=logger(), optimizer=Cma_cpp(100000))
ret = retry.minimize(fun, bounds, logger=logger(), optimizer=Sequence([De_cpp(50000), Cma_cpp(50000)]))
----

Here https://github.com/dietmarwo/fast-cma-es/blob/master/examples/examples.py[examples.py] you find examples.
Check the https://github.com/dietmarwo/fast-cma-es/blob/master/tutorials/Tutorial.adoc[Tutorial] for more details. 

In https://github.com/dietmarwo/fast-cma-es/blob/master/examples/advexamples.py[tutorial.py] and https://github.com/dietmarwo/fast-cma-es/blob/master/examples/advexamples.py[advexamples.py] you find examples for the smart retry. 

=== Log output of the parallel retry

The log output of the parallel retry contains the following rows:

===== Parallel retry

- time (in sec)
- evaluations / sec
- number of retries - optimization runs
- total number of evaluations in all retries
- best value found so far
- mean of the values found by the retries below the defined threshold
- standard deviation of the values found by the retries below the defined threshold
- list of the best 20 function values in the retry store
- best solution (x-vector) found so far

Mean and standard deviation would be misleading when using coordinated retry, because
of the retries initiated by crossover. Therefore the rows of the
log output differ slightly:
 
===== Smart retry

- time (in sec)
- evaluations / sec
- number of retries - optimization runs
- total number of evaluations in all retries
- best value found so far
- worst value in the retry store
- number of entries in the retry store
- list of the best 20 function values in the retry store
- best solution (x-vector) found so far

=== Dependencies

Runtime:

- numpy: https://github.com/numpy/numpy
- scipy: https://github.com/scipy/scipy

Compile time (binaries for Linux and Windows are included):

- Eigen https://gitlab.com/libeigen/eigen (version >= 3.9 is required for CMA).
- pcg-cpp: https://github.com/imneme/pcg-cpp - used in all {cpp} optimization algorithms.
- LBFGSpp: https://github.com/yixuan/LBFGSpp/tree/master/include - used for dual annealing local optimization.

Optional dependencies:

- NLopt: https://nlopt.readthedocs.io/en/latest/[NLopt]. Install with 'pip install nlopt'. 
- pygmo2: https://github.com/esa/pygmo2[pygmo]. Install with 'pip install pygmo'. 

Example dependencies:

- pykep: https://esa.github.io/pykep/[pykep]. Install with 'pip install pykep'. 

=== ESAs Messenger-Full Space Trajectory Design Problem

Because of its famous complexity ESAs 26-dimensional https://www.esa.int/gsp/ACT/projects/gtop/messenger_full/[Messenger full] 
problem is often referenced in the literature, see for instance http://www.midaco-solver.com/data/pub/PDPTA20_Messenger.pdf[MXHCP paper].

fcmaes is the only library capable of solving it using a single CPU: 
In about 1950 seconds on average using an AMD 5950x (1250 seconds for the 
https://github.com/dietmarwo/fcmaes-java[java] variant) .

The Problem models a multi-gravity assist interplanetary space mission from Earth to Mercury. In 2009 the first good solution (6.9 km/s) was submitted. It took more than five years to reach 1.959 km/s and three more years until 2017 to find the optimum 1.958 km/s. The picture below shows the progress of the whole science community since 2009:

image::Fsc.png[]  

The following picture shows 101 coordinated retry runs: 

image::mf3.6000.png[]  

60 out of these 101 runs produced a result better than 2 km/s:

image::mf3.2000.png[] 

About 1.2*10^6 function evaluations per second were performed which shows excellent scaling of the algorithm utilizing all 16 cores / 32 threads.  
https://github.com/dietmarwo/fcmaes-java/blob/master/README.adoc shows that the fcmaes java implementation sharing 
the same C++ code is significantly faster. 
https://github.com/dietmarwo/fcmaes-ray/blob/master/README.adoc[fcmaesray] shows how a 5 node cluster using 
96 CPU-cores executing fcmaes coordinated retry performs in comparison.

=== Citing

[source]
----
@misc{fcmaes2022,
    author = {Dietmar Wolz},
    title = {fcmaes - A Python-3 derivative-free optimization library},
    note = {Python/C++ source code, with description and examples},
    year = {2022},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {Available at \url{https://github.com/dietmarwo/fast-cma-es}},
}
----
